{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79055ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tested.csv',names=['P_ID',\t'Survived',\t'Pclass'\t,'P_Name',\t'Gender',\t'Age',\t'Sibling or Spouse'\t,'Parch',\t'Ticket_ID'\t,'Fare',\t'Cabin',\t'Starting_Journey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b397b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#header-> header parameter make sure that the row name will be shown as the column name based on indexing of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c60db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tested.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_col-> index_col parameter make sure that the row name will be shown as the column name based on indexing of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tested.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to use converters-> converters parameter is used to convert the data type of the column while reading the dataset\n",
    "#pd.read_csv('tested.csv', converters={'Embarked': lambda x: 'Queenland' if x == 'Q' else x})\n",
    "\n",
    "def Station(value):\n",
    "    if value=='Q':\n",
    "        return 'Queenland'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tested.csv',converters={'Embarked':Station})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66248715",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('D:/visual studio/Module and packages/Matplotlib/student_depression_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca44fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usecols->wjat columns we should use to show out of all of the columns we are having the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52817212",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('D:/visual studio/Module and packages/Matplotlib/student_depression_dataset.csv',usecols=['id',\t'Gender',\t'Age',\t'City',\t'Profession',\t'Academic Pressure',\t'CGPA',\t'Study Satisfaction',\t'Job Satisfaction',\t'Sleep Duration',\t'Dietary Habits',\t'Degree',\t'Have you ever had suicidal thoughts ?',\t\t'Depression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d726cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#squeeze--> dataframe--> series---> squeeze--> True--> combination of usecols and squeeze-> true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tested.csv',usecols=['Survived']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nrows-> it is going to help us with a fixed number of rows out of the complete data -> 100-> only 100 rows out of all the rows willbe shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c06ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('D:/visual studio/Module and packages/Matplotlib/student_depression_dataset.csv',nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding issue-> utf-8->manually keep the encoding as utf-8 and then try to read the dataset\n",
    "\n",
    "#encoding -> it makes sure that data we are reading is in utf-8 format-> encoding='latin-1'\n",
    "#data2=pd.read_csv('Global YouTube Statistics.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d97deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old\n",
    "#pd.read_csv(\"tested.csv\", error_bad_lines=False)\n",
    "\n",
    "# new equivalent (skip bad rows)\n",
    "#pd.read_csv(\"tested.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "# error_bad_lines-> it is going to ignore the bad lines and it will not show any error and it will read the complete dataset without showing any error -> error_bad_lines=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtypes-> it can assign initially only with a specific data type to columns-> dtypes={'col1':str,'col2':int}--> it is going to assign the data type of col1 as string and col2 as integer           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fa8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('tested.csv', dtype={'Age': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chocsales=pd.read_csv('D:/visual studio/Module and packages/Matplotlib/Chocolate Sales.csv',parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f861253",
   "metadata": {},
   "outputs": [],
   "source": [
    "chocsales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3faaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chocsales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa22539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#na_values-> it is going to replace the values which are mentioned in na_values with NaN values\n",
    "pd.read_csv('tested.csv',na_values=['NA','Missing','Not Available'])    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f8d1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a huge dataset-> chunksize=num_valie-->20000--> 5000 in every dataframe--> chunksize=5000\n",
    "dfs=pd.read_csv('D:/visual studio/Module and packages/Matplotlib/student_depression_dataset.csv',chunksize=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b994d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x135ff56cb90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16829e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_1.csv\n",
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_2.csv\n",
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_3.csv\n",
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_4.csv\n",
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_5.csv\n",
      "D:\\visual studio\\Module and packages\\MachineLearning\\saved_chunks\\chunk_6.csv\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# save_dir = Path.cwd() / \"saved_chunks\"   # current notebook working folder + subfolder\n",
    "# save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# for i, chunk in enumerate(dfs, start=1):\n",
    "#     out_file = save_dir / f\"chunk_{i}.csv\"\n",
    "#     chunk.to_csv(out_file, index=False)\n",
    "#     print(out_file.resolve())   # full path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf85b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\visual studio\\Module and packages\\MachineLearning\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# print(Path.cwd())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
